[Node]
token = 

[Server]
URL = http://YOUR_SERVER_IP:5000

[LLM]
bin = C:\llama.cpp\llama-server.exe
gpu_layers = 99
port_start = 11000
port_end = 12000

[Model:tinyllama]
path = C:\llama.cpp\models\tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
context = 2048
