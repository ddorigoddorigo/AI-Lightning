{
  "models": {
    "79801dfd6f27dcae": {
      "id": "79801dfd6f27dcae",
      "name": "30B",
      "filename": "unsloth/Nemotron-3-Nano-30B-A3B-GGUF",
      "filepath": "",
      "size_bytes": 16106127360,
      "size_gb": 15.0,
      "parameters": "30B",
      "quantization": "Unknown",
      "context_length": 4096,
      "architecture": "unknown",
      "created_at": "2026-02-02T16:33:55.459879",
      "min_vram_mb": 18000,
      "recommended_vram_mb": 27000,
      "enabled": true,
      "hf_repo": "unsloth/Nemotron-3-Nano-30B-A3B-GGUF",
      "is_huggingface": true,
      "last_used": "",
      "use_count": 0
    },
    "100a6ff7dabb3049": {
      "id": "100a6ff7dabb3049",
      "name": "Llama 3B Q4_K_M",
      "filename": "unsloth/Llama-3.2-3B-Instruct-GGUF:Q4_K_M",
      "filepath": "",
      "size_bytes": 1610612736,
      "size_gb": 1.5,
      "parameters": "3B",
      "quantization": "Q4_K_M",
      "context_length": 4096,
      "architecture": "llama",
      "created_at": "2026-02-02T17:11:51.648586",
      "min_vram_mb": 2500,
      "recommended_vram_mb": 4000,
      "enabled": true,
      "hf_repo": "unsloth/Llama-3.2-3B-Instruct-GGUF:Q4_K_M",
      "is_huggingface": true,
      "last_used": "",
      "use_count": 0
    }
  },
  "updated_at": "2026-02-02T17:11:51.648622"
}